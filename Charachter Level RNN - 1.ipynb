{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about classifying names, by building a Charachter Level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/data/names\\\\Arabic.txt', 'data/data/names\\\\Chinese.txt', 'data/data/names\\\\Czech.txt', 'data/data/names\\\\Dutch.txt', 'data/data/names\\\\English.txt', 'data/data/names\\\\French.txt', 'data/data/names\\\\German.txt', 'data/data/names\\\\Greek.txt', 'data/data/names\\\\Irish.txt', 'data/data/names\\\\Italian.txt', 'data/data/names\\\\Japanese.txt', 'data/data/names\\\\Korean.txt', 'data/data/names\\\\Polish.txt', 'data/data/names\\\\Portuguese.txt', 'data/data/names\\\\Russian.txt', 'data/data/names\\\\Scottish.txt', 'data/data/names\\\\Spanish.txt', 'data/data/names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "def get_Files(path): return glob.glob(path)\n",
    "\n",
    "print(get_Files('data/data/names/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the names are in Unicode format. However, we have to convert them to ASCII standard. This will remove the diacritics in the words. For example, the French name Béringer will be converted to Beringer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "print(type(string.ascii_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the string.ascii_letters is a class but we need the string of all ascii letters for our function that will convert text from unicode to ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "Beringer\n"
     ]
    }
   ],
   "source": [
    "all_letters = string.ascii_letters + \".,;'\"\n",
    "n_letters = len(all_letters)\n",
    "print(n_letters)\n",
    "\n",
    "def unicodeToASCII(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToASCII('Béringer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a dictionary of languages, and all the names assosciated to that language in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "all_categories = []\n",
    "\n",
    "def readFiles(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToASCII(line) for line in lines]\n",
    "\n",
    "for filename in get_Files('data/data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readFiles(filename)\n",
    "    final_dict[category] = lines\n",
    "    \n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Khoury', 'Nahas', 'Daher', 'Gerges', 'Nazari']\n"
     ]
    }
   ],
   "source": [
    "print(final_dict['Arabic'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the neural network we need to convert the charachters into tensors. We will use one hot encoding. A line can be obtained by stacking the one hot tensors of the charachters in that line together in a single vector that is join multiple vectors into a 2D matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "torch.Size([5, 1, 56])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# sample testing\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch tensors are mutable, but in tensorflow this is not possible. So to create a similar tensor as above what we can do is create a numpy array and when that array is created in the above format then convert it to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(hidden_size + input_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size + input_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        combined = torch.cat((inputs, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        outputs = self.i2o(combined)\n",
    "        outputs = self.softmax(outputs)\n",
    "        return outputs, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = letterToTensor('A')\n",
    "outputs, hidden = rnn(inputs, torch.zeros(1, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8891, -2.8873, -2.9206, -2.8567, -2.8909, -2.9423, -2.9277, -2.8792,\n",
      "         -2.9101, -2.8580, -2.8541, -2.9434, -2.8125, -2.9714, -2.9975, -2.8699,\n",
      "         -2.8844, -2.7586]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vietnamese', 17)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category = top_i[0].item()\n",
    "    return all_categories[category], category\n",
    "\n",
    "print(categoryFromOutput(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Getting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomNumber(l): return l[random.randint(0, len(l)-1)]\n",
    "\n",
    "def randomExample():\n",
    "    # selects a random category from the all \n",
    "    # categories list\n",
    "    category = randomNumber(all_categories)\n",
    "    \n",
    "    # selects a random name from the list of \n",
    "    # names under that category\n",
    "    line = randomNumber(final_dict[category])\n",
    "    \n",
    "    # convert both the name and category to\n",
    "    # tensor to be able to work with the \n",
    "    # neural network\n",
    "    category_tensor = torch.tensor([all_categories.index(category)])\n",
    "    line_tensor = lineToTensor(line)\n",
    "    \n",
    "    return category, line, category_tensor, line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss for training the neural network\n",
    "criterion = nn.NLLLoss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
